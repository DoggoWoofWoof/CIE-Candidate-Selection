{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import output\n",
        "from google.colab import files\n",
        "\n",
        "file_selector = files.upload()\n",
        "\n",
        "if not file_selector:\n",
        "  print(\"No file selected.\")\n",
        "\n",
        "uploaded_file = next(iter(file_selector.values()))\n",
        "\n",
        "try:\n",
        "  if not uploaded_file.name.endswith(\".xlsx\"):\n",
        "    print(\"Please select an .xlsx file.\")\n",
        "except:\n",
        "  print(\"Please check file type\")\n",
        "\n",
        "with open(\"/content/data.xlsx\", \"wb\") as f:\n",
        "  f.write(uploaded_file)\n",
        "\n",
        "# Print a success message\n",
        "print(\"File uploaded and saved as data.xlsx.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "4eW-0FAtYhr0",
        "outputId": "e855cf5d-699b-429e-bff2-3030cb3ae6f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b499778f-48f4-48f8-ac18-3b7e777584e8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b499778f-48f4-48f8-ac18-3b7e777584e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.xlsx to data.xlsx\n",
            "Please check file type\n",
            "File uploaded and saved as data.xlsx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/Model/\"\n",
        "!clear\n",
        "!wget https://github.com/ujwalnk/CIE-Candidate-Selection/raw/main/Models/model-bert-use-this.hdf5\n",
        "!clear\n",
        "!mv \"/content/model-bert-use-this.hdf5\" \"/content/Model/model-bert-use-this.hdf5\"\n",
        "!clear\n",
        "!wget https://github.com/ujwalnk/CIE-Candidate-Selection/raw/main/Models/model_weights_and_optimizer.pickle\n",
        "!clear\n",
        "!mv \"/content/model_weights_and_optimizer.pickle\" \"/content/Model/model_weights_and_optimizer.pickle\"\n",
        "!clear\n",
        "!wget https://github.com/ujwalnk/CIE-Candidate-Selection/raw/main/Models/random_forest_model.joblib\n",
        "!clear\n",
        "!mv \"/content/random_forest_model.joblib\" \"/content/Model/random_forest_model.joblib\"\n",
        "!clear\n",
        "!wget https://github.com/ujwalnk/CIE-Candidate-Selection/raw/main/Models/vectorizer.joblib\n",
        "!clear\n",
        "!mv \"/content/vectorizer.joblib\" \"/content/Model/vectorizer.joblib\"\n",
        "!clear"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giZHK9_aDsh6",
        "outputId": "6dd06e72-2dba-4024-8de1-9aca6664b3a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[H\u001b[2J--2024-04-19 16:30:01--  https://github.com/ujwalnk/CIE-Candidate-Selection/raw/main/Models/model-bert-use-this.hdf5\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ujwalnk/CIE-Candidate-Selection/main/Models/model-bert-use-this.hdf5 [following]\n",
            "--2024-04-19 16:30:01--  https://raw.githubusercontent.com/ujwalnk/CIE-Candidate-Selection/main/Models/model-bert-use-this.hdf5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 418600 (409K) [application/octet-stream]\n",
            "Saving to: ‘model-bert-use-this.hdf5’\n",
            "\n",
            "model-bert-use-this 100%[===================>] 408.79K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-04-19 16:30:01 (11.2 MB/s) - ‘model-bert-use-this.hdf5’ saved [418600/418600]\n",
            "\n",
            "\u001b[H\u001b[2J\u001b[H\u001b[2J--2024-04-19 16:30:01--  https://github.com/ujwalnk/CIE-Candidate-Selection/raw/main/Models/model_weights_and_optimizer.pickle\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ujwalnk/CIE-Candidate-Selection/main/Models/model_weights_and_optimizer.pickle [following]\n",
            "--2024-04-19 16:30:02--  https://raw.githubusercontent.com/ujwalnk/CIE-Candidate-Selection/main/Models/model_weights_and_optimizer.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132137 (129K) [application/octet-stream]\n",
            "Saving to: ‘model_weights_and_optimizer.pickle’\n",
            "\n",
            "model_weights_and_o 100%[===================>] 129.04K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-04-19 16:30:02 (5.57 MB/s) - ‘model_weights_and_optimizer.pickle’ saved [132137/132137]\n",
            "\n",
            "\u001b[H\u001b[2J\u001b[H\u001b[2J--2024-04-19 16:30:02--  https://github.com/ujwalnk/CIE-Candidate-Selection/raw/main/Models/random_forest_model.joblib\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ujwalnk/CIE-Candidate-Selection/main/Models/random_forest_model.joblib [following]\n",
            "--2024-04-19 16:30:02--  https://raw.githubusercontent.com/ujwalnk/CIE-Candidate-Selection/main/Models/random_forest_model.joblib\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 656169 (641K) [application/octet-stream]\n",
            "Saving to: ‘random_forest_model.joblib’\n",
            "\n",
            "random_forest_model 100%[===================>] 640.79K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-04-19 16:30:02 (14.5 MB/s) - ‘random_forest_model.joblib’ saved [656169/656169]\n",
            "\n",
            "\u001b[H\u001b[2J\u001b[H\u001b[2J--2024-04-19 16:30:03--  https://github.com/ujwalnk/CIE-Candidate-Selection/raw/main/Models/vectorizer.joblib\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ujwalnk/CIE-Candidate-Selection/main/Models/vectorizer.joblib [following]\n",
            "--2024-04-19 16:30:03--  https://raw.githubusercontent.com/ujwalnk/CIE-Candidate-Selection/main/Models/vectorizer.joblib\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4314596 (4.1M) [application/octet-stream]\n",
            "Saving to: ‘vectorizer.joblib’\n",
            "\n",
            "vectorizer.joblib   100%[===================>]   4.11M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-04-19 16:30:03 (55.5 MB/s) - ‘vectorizer.joblib’ saved [4314596/4314596]\n",
            "\n",
            "\u001b[H\u001b[2J\u001b[H\u001b[2J"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify that the excel file has been added to the current directory.\n",
        "\n",
        "> Need to verify later if the pickle files of both @Sairam & @Swastik are added to the current directory"
      ],
      "metadata": {
        "id": "7hpyg0p5u7dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Please Be Patient\"\n",
        "!pip install tensorflow_text -q\n",
        "!pip install --upgrade tf-keras -q\n",
        "!pip install aspose-cells -q\n",
        "!echo \"Thank You For Your Patience\""
      ],
      "metadata": {
        "id": "xwdJFQYMtTAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b19996-482b-4028-c5f7-6decb3722be0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Be Patient\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hThank You For Your Patience\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3LROco7mhuki"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "full_dataframe = pd.read_excel('/content/data.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sairam 7 questions\n",
        "\n",
        "questions = [\n",
        "    \"Give one/top reason why you want to take up this course\",\n",
        "    \"What (one/top thing) do you expect to get out of this course?\",\n",
        "    \"What does entrepreneurship mean to you?\",\n",
        "    \"Can you give one example of any prototype you have built?\",\n",
        "    \"Optional question: Are you excited to work on any ideas/opportunities as part of this course. If so please elaborate.\"\n",
        "  ]"
      ],
      "metadata": {
        "id": "PnJaWF1TjDc3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI Component Detection Below"
      ],
      "metadata": {
        "id": "QQb4OknjwpR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#run this cell once before predicting values (loading the model)\n",
        "#Accuracy of the model = 82-86%\n",
        "import tensorflow\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text  # Registers the ops.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class BertEncoder(tensorflow.keras.layers.Layer):\n",
        "    def __init__(self, preprocess_path, model_path, **kwargs):\n",
        "        super(BertEncoder, self).__init__(**kwargs)\n",
        "        self.preprocessor = hub.KerasLayer(preprocess_path)\n",
        "        self.encoder = hub.KerasLayer(model_path, trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        encoder_inputs = self.preprocessor(inputs)\n",
        "        outputs = self.encoder(encoder_inputs)\n",
        "        pooled_output = outputs['pooled_output']  # [batch_size, 512].\n",
        "        sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 512].\n",
        "        return pooled_output, sequence_output\n",
        "\n",
        "with tensorflow.keras.utils.custom_object_scope({'BertEncoder': BertEncoder}):\n",
        "    # Load the model architecture and weights\n",
        "    model = tensorflow.keras.models.load_model('/content/Model/model-bert-use-this.hdf5')\n",
        "\n",
        "# Load model weights and optimizer state from pickle file\n",
        "with open('/content/Model/model_weights_and_optimizer.pickle', 'rb') as f:\n",
        "    weights, optimizer_config = pickle.load(f)\n",
        "\n",
        "# Set model weights\n",
        "model.set_weights(weights)\n",
        "\n",
        "# Reconstruct optimizer from config\n",
        "optimizer = tensorflow.keras.optimizers.Adam.from_config(optimizer_config)\n",
        "\n",
        "print(\"Model Loaded\")"
      ],
      "metadata": {
        "id": "o-SD023XlbCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ccb8f1-6f15-4514-e583-b8623d640ebc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_main=[]\n",
        "for i in questions:\n",
        "  temp1=[]\n",
        "  y_pred=model.predict(full_dataframe[i].fillna(\"NA\"))\n",
        "  for j in y_pred:\n",
        "    temp1.append(j[0])\n",
        "  y_pred\n",
        "  y_main.append(temp1)"
      ],
      "metadata": {
        "id": "RrDLPZ6zxQWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f33239-c274-44b4-cea8-9718fcf1de52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4s/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_main = [list(i) for i in zip(*y_main)]#transposing the matrix\n",
        "ai_df=pd.DataFrame(y_main)"
      ],
      "metadata": {
        "id": "4z8gBbB45JWI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing Below"
      ],
      "metadata": {
        "id": "eBsPI2OpwqbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your output df will be like this I presume, please use the same variable names.\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "from joblib import load\n",
        "\n",
        "# Load the vectorizer\n",
        "loaded_vectorizer = load('/content/Model/vectorizer.joblib')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load('/content/Model/random_forest_model.joblib')\n",
        "\n",
        "# Read the data from data.xlsx\n",
        "data_df = full_dataframe #pd.read_excel('/content/CIE L1_Aug2023 semester_OAT data.xlsx')\n",
        "\n",
        "# Assuming the text responses are in columns 7 onwards\n",
        "text_columns = data_df.columns[7:]\n",
        "\n",
        "# Iterate over each row and make predictions\n",
        "for index, row in data_df.iterrows():\n",
        "    # Concatenate all text responses into a single string https://www.canva.com/design/DAGCG5bJlhs/ZaWlO8EVoVCsPdDpJqnM0A/edit?utm_content=DAGCG5bJlhs&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton\n",
        "    answers_row = ' '.join(row[text_columns].astype(str))\n",
        "\n",
        "    # Transform the text using the loaded vectorizer\n",
        "    answers_row_vec = loaded_vectorizer.transform([answers_row])\n",
        "\n",
        "    # Make prediction for the row\n",
        "    prediction = loaded_model.predict(answers_row_vec)\n",
        "\n",
        "    # Print the predicted status\n",
        "    predicted_status = 'confirmed' if prediction[0] == 1 else 'not confirmed'"
      ],
      "metadata": {
        "id": "3wwkm6Xwwx78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdcc1761-715e-43b5-cca0-192d10020d8b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           0\n",
            "0   0.352919\n",
            "1   0.135857\n",
            "2   0.992115\n",
            "3   0.739386\n",
            "4   0.340593\n",
            "..       ...\n",
            "95  0.970884\n",
            "96  0.372537\n",
            "97  0.049686\n",
            "98  0.059132\n",
            "99  0.862416\n",
            "\n",
            "[100 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from joblib import load\n",
        "\n",
        "# Load the vectorizer and model\n",
        "loaded_vectorizer = load('/content/Model/vectorizer.joblib')\n",
        "loaded_model = load('/content/Model/random_forest_model.joblib')\n",
        "\n",
        "# Assume data_df is already defined and includes the required data\n",
        "text_columns = data_df.columns[7:]\n",
        "\n",
        "# List to store each row's data\n",
        "data = []\n",
        "\n",
        "# Iterate over rows in the dataframe\n",
        "for index, row in full_dataframe.iterrows():\n",
        "    # Vectorize the given row\n",
        "    answers_row = ' '.join(row[text_columns].astype(str))\n",
        "    answers_row_vec = loaded_vectorizer.transform([answers_row])\n",
        "\n",
        "    # Predict the probability of the confirmed class\n",
        "    probability = loaded_model.predict_proba(answers_row_vec)[:, 1]\n",
        "\n",
        "    # Append dictionary to list\n",
        "    data.append({'probability': float(probability[0])})\n",
        "\n",
        "# Create DataFrame from list of dictionaries\n",
        "results_df = pd.DataFrame(data)\n",
        "\n",
        "# Optionally, to see the first few rows of your DataFrame:\n",
        "# print(results_df.head())\n",
        "\n",
        "nlp_df = results_df"
      ],
      "metadata": {
        "id": "7H7ifGDEihcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da140ed-d440-4b77-bf47-d6a63d84de5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   probability\n",
            "0     0.304626\n",
            "1     0.398175\n",
            "2     0.348375\n",
            "3     0.349435\n",
            "4     0.295705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outputting to the Excel File"
      ],
      "metadata": {
        "id": "dTeQbzdww2NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# I am dividing it here to normalize the score\n",
        "\n",
        "ai_df.loc[:, \"AI Component\"] = ai_df.sum(axis=1) / 5\n",
        "ai_df = ai_df[[\"AI Component\"]]\n",
        "\n",
        "temp_df = full_dataframe\n",
        "temp_df = pd.concat([temp_df, ai_df, nlp_df], axis=1)\n",
        "temp_df.to_excel(\"/content/output.xlsx\", index=True)\n",
        "\n",
        "print(\"Output File Created!\")"
      ],
      "metadata": {
        "id": "2WRZPRzrw3rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d8fcc5-2832-45be-8eb6-a3df7c45d07f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output File Created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Database"
      ],
      "metadata": {
        "id": "YVlnZKg0694p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3 as s\n",
        "import datetime\n",
        "\n",
        "def write_2_db(c, connection, param, value):\n",
        "  c.execute(\"\"\"\n",
        "    INSERT INTO GRAPH_DATA (PARAM, YEAR, MONTH, VALUE) VALUES (?, ?, ?, ?)\n",
        "  \"\"\", (param, datetime.date.today().year, datetime.date.today().month, value))\n",
        "\n",
        "  # Save the transaction\n",
        "  connection.commit()\n",
        "\n",
        "connection = s.connect(\"/content/base.sqlite\")\n",
        "\n",
        "c = connection.cursor()\n",
        "\n",
        "# Create a new table\n",
        "c.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS GRAPH_DATA (\n",
        "        PARAM TEXT NOT NULL,\n",
        "        YEAR INT NOT NULL,\n",
        "        MONTH INT NOT NULL,\n",
        "        VALUE INT NOT NULL\n",
        "    )\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "g08xEuLCXR9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687f442a-73f5-47d7-adbb-bf56db53ed91"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x79ee55c33e40>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "write_2_db(c, connection, \"AI\", int(ai_df.mean()[\"AI Component\"] * 100))\n",
        "\n",
        "write_2_db(c, connection, \"Branch/CS\", int(full_dataframe[\"Branch\"].value_counts()[\"CS\"]))\n",
        "write_2_db(c, connection, \"Branch/EC\", int(full_dataframe[\"Branch\"].value_counts()[\"ECE\"]))\n",
        "write_2_db(c, connection, \"Branch/EE\", int(full_dataframe[\"Branch\"].value_counts()[\"EEE\"]))\n",
        "write_2_db(c, connection, \"Branch/AI\", int(full_dataframe[\"Branch\"].value_counts()[\"AIML\"]))\n",
        "write_2_db(c, connection, \"Branch/BT\", int(full_dataframe[\"Branch\"].value_counts()[\"Biotech\"]))\n",
        "write_2_db(c, connection, \"Branch/ME\", int(full_dataframe[\"Branch\"].value_counts()[\"Mech\"]))\n",
        "\n",
        "def get_year(x, y):\n",
        "  sum = 0\n",
        "  try:\n",
        "    sum += int(full_dataframe[\"Semester\"].value_counts()[x])\n",
        "  except:\n",
        "    try:\n",
        "      sum += int(full_dataframe[\"Semester\"].value_counts()[y])\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  return sum\n",
        "\n",
        "write_2_db(c, connection, \"YEAR/1\", int(get_year(\"1st\",\"2nd\")))\n",
        "write_2_db(c, connection, \"YEAR/2\", int(get_year(\"3rd\",\"4th\")))\n",
        "write_2_db(c, connection, \"YEAR/3\", int(get_year(\"5th\",\"6th\")))\n",
        "write_2_db(c, connection, \"YEAR/4\", int(get_year(\"7th\",\"8th\")))\n",
        "\n",
        "c.execute(\"SELECT * from GRAPH_DATA\")\n",
        "db_output = c.fetchall()"
      ],
      "metadata": {
        "id": "XknbOL-YauC5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting the data into Excel file charts"
      ],
      "metadata": {
        "id": "ycD40ZcpOM0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Convert data to DataFrame\n",
        "df = pd.DataFrame(db_output, columns=['Parameter', 'Year', 'Month', 'Value'])\n",
        "\n",
        "# Pivot the DataFrame to get the desired format\n",
        "pivot_df = df.pivot_table(index='Parameter', columns=['Year', 'Month'], values='Value', aggfunc='sum', fill_value=0)\n",
        "\n",
        "# Flatten the multi-level columns\n",
        "pivot_df.columns = [f'{col[0]}-{col[1]}' for col in pivot_df.columns]\n",
        "\n",
        "# Write the formatted data to Excel\n",
        "excel_file_path = '/content/formatted_data.xlsx'\n",
        "with pd.ExcelWriter(excel_file_path) as writer:\n",
        "    pivot_df.to_excel(writer, sheet_name='Formatted Data')\n",
        "\n",
        "print(f'Formatted data has been written to {excel_file_path}')\n"
      ],
      "metadata": {
        "id": "BapyrJnZOQfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b3715a-74d6-418e-de49-f599c87dc91e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formatted data has been written to /content/formatted_data.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AI COMPONENT GRAPH\n",
        "import jpype\n",
        "import asposecells\n",
        "jpype.startJVM()\n",
        "from asposecells.api import Workbook, ChartType, FileFormatType\n",
        "\n",
        "workbook = Workbook(\"/content/formatted_data.xlsx\")\n",
        "worksheet = workbook.getWorksheets().get(0)\n",
        "\n",
        "data_range=len([str(db_output[x][1])  + \"-\" + str(db_output[x][2]) for x in range(0, len(db_output), 11)])\n",
        "\n",
        "chartIndex = worksheet.getCharts().add(ChartType.COLUMN, 6, 2, 22, 10)\n",
        "chart = worksheet.getCharts().get(chartIndex)\n",
        "chart.setChartDataRange(f\"A1:{chr(ord('A')+data_range)}2\", True)\n",
        "\n",
        "chartIndex_branch = worksheet.getCharts().add(ChartType.COLUMN, 6, 20, 22, 30)\n",
        "chart_branch = worksheet.getCharts().get(chartIndex_branch)\n",
        "chart_branch.setChartDataRange(f\"A3:C8\", True)\n",
        "\n",
        "chartIndex_year = worksheet.getCharts().add(ChartType.COLUMN, 6, 15, 22, 25)\n",
        "chart_year = worksheet.getCharts().get(chartIndex_year)\n",
        "chart_year.setChartDataRange(f\"A9:C12\", True)\n",
        "\n",
        "# Save the Excel file\n",
        "workbook.save(\"excel-column-chart.xlsx\")"
      ],
      "metadata": {
        "id": "YfS2Xes1rvhg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "!echo \"Please allow multiple files downloads if all files are not getting downloaded\"\n",
        "\n",
        "files.download('/content/excel-column-chart.xlsx')\n",
        "files.download('/content/output.xlsx')\n",
        "files.download('/content/base.sqlite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nJ9rXpDQOclR",
        "outputId": "31bbf9f2-b793-412b-8e52-78cd6e20d973"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7a250ebb-c72b-4272-b773-fd118029e384\", \"excel-column-chart.xlsx\", 12856)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e4459125-3161-49c3-b8ec-21a83480dc1c\", \"output.xlsx\", 462774)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e4693bbc-07eb-4267-be15-95c797915ae4\", \"base.sqlite\", 8192)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}