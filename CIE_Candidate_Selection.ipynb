{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import output\n",
        "from google.colab import files\n",
        "\n",
        "file_selector = files.upload()\n",
        "\n",
        "if not file_selector:\n",
        "  print(\"No file selected.\")\n",
        "\n",
        "uploaded_file = next(iter(file_selector.values()))\n",
        "\n",
        "try:\n",
        "  if not uploaded_file.name.endswith(\".xlsx\"):\n",
        "    print(\"Please select an .xlsx file.\")\n",
        "except:\n",
        "  print(\"Please check file type\")\n",
        "\n",
        "with open(\"/content/data.xlsx\", \"wb\") as f:\n",
        "  f.write(uploaded_file)\n",
        "\n",
        "# Print a success message\n",
        "print(\"File uploaded and saved as data.xlsx.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "4eW-0FAtYhr0",
        "outputId": "083aa4f1-e8bd-4f3e-c58c-244ef8f7e439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6abfbeca-2940-4d3b-9483-6acef1b85f25\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6abfbeca-2940-4d3b-9483-6acef1b85f25\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CIE L1_Aug2023 semester_OAT data.xlsx to CIE L1_Aug2023 semester_OAT data.xlsx\n",
            "Please check file type\n",
            "File uploaded and saved as data.xlsx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify that the excel file has been added to the current directory.\n",
        "\n",
        "> Need to verify later if the pickle files of both @Sairam & @Swastik are added to the current directory"
      ],
      "metadata": {
        "id": "7hpyg0p5u7dd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LROco7mhuki"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "full_dataframe = pd.read_excel('/content/data.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sairam 7 questions\n",
        "\n",
        "questions = [\n",
        "    \"Give one/top reason why you want to take up this course\",\n",
        "    \"What (one/top thing) do you expect to get out of this course?\",\n",
        "    \"What does entrepreneurship mean to you?\",\n",
        "    \"Can you give one example of any prototype you have built?\",\n",
        "    \"Optional question: Are you excited to work on any ideas/opportunities as part of this course. If so please elaborate.\"\n",
        "  ]\n",
        "\n"
      ],
      "metadata": {
        "id": "PnJaWF1TjDc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI Component Detection Below"
      ],
      "metadata": {
        "id": "QQb4OknjwpR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwdJFQYMtTAF",
        "outputId": "8a72bdfa-0cd4-4714-ea8b-3aefb78d000e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "Collecting keras>=3.0.0 (from tensorflow)\n",
            "  Using cached keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.1\n",
            "    Uninstalling tensorflow-2.15.1:\n",
            "      Successfully uninstalled tensorflow-2.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#run this cell once before predicting values (loading the model)\n",
        "#Accuracy of the model = 82-86%\n",
        "import tensorflow\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text  # Registers the ops.\n",
        "import numpy as np\n",
        "\n",
        "class BertEncoder(tensorflow.keras.layers.Layer):\n",
        "    def __init__(self, preprocess_path, model_path, **kwargs):\n",
        "        super(BertEncoder, self).__init__(**kwargs)\n",
        "        self.preprocessor = hub.KerasLayer(preprocess_path)\n",
        "        self.encoder = hub.KerasLayer(model_path, trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        encoder_inputs = self.preprocessor(inputs)\n",
        "        outputs = self.encoder(encoder_inputs)\n",
        "        pooled_output = outputs['pooled_output']  # [batch_size, 512].\n",
        "        sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 512].\n",
        "        return pooled_output, sequence_output\n",
        "\n",
        "with tensorflow.keras.utils.custom_object_scope({'BertEncoder': BertEncoder}):\n",
        "    # Load the model architecture and weights\n",
        "    model = tensorflow.keras.models.load_model('/content/Model/model-bert-use-this.hdf5')\n",
        "\n",
        "# Load model weights and optimizer state from pickle file\n",
        "with open('/content/Model/model_weights_and_optimizer.pickle', 'rb') as f:\n",
        "    weights, optimizer_config = pickle.load(f)\n",
        "\n",
        "# Set model weights\n",
        "model.set_weights(weights)\n",
        "\n",
        "# Reconstruct optimizer from config\n",
        "optimizer = tensorflow.keras.optimizers.Adam.from_config(optimizer_config)\n",
        "\n",
        "print(\"Model Loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "o-SD023XlbCU",
        "outputId": "eb80fc79-f471-440f-99d1-9d90e8adc427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a9ceaa878051>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_text\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext\u001b[0m  \u001b[0;31m# Registers the ops.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0m_ensure_keras_2_importable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m_ensure_keras_2_importable\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mversion_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mversion_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       \u001b[0;32mimport\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0;31m# Print more informative error message, then reraise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__internal__/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_initialize_variables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minitialize_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrack_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/applications/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtLarge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtSmall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/applications/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/sequential.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlegacy_sm_saving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_model_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/saved_model/load_context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_load_context_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_load_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_main=[]\n",
        "for i in questions:\n",
        "  temp1=[]\n",
        "  y_pred=model.predict(full_dataframe[i].fillna(\"NA\"))\n",
        "  for j in y_pred:\n",
        "    temp1.append(j[0])\n",
        "  y_pred\n",
        "  y_main.append(temp1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "RrDLPZ6zxQWm",
        "outputId": "b24c0274-89ac-49ee-9d62-0373aaf7f802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-49bc7b23fbc4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtemp1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtemp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_main = [list(i) for i in zip(*y_main)]#transposing the matrix\n",
        "ai_df=pd.DataFrame(y_main)"
      ],
      "metadata": {
        "id": "4z8gBbB45JWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_df # Contains the value of how probable the sentence was AI written"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "z9OkmVr7jhJO",
        "outputId": "deaa531a-4d5e-405e-ee05-06f322ccfe49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-815a8e9b-30fc-4de1-84c4-13c4e379c712\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-815a8e9b-30fc-4de1-84c4-13c4e379c712')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-815a8e9b-30fc-4de1-84c4-13c4e379c712 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-815a8e9b-30fc-4de1-84c4-13c4e379c712');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_79bd4fd1-b045-4f68-a59a-0504e562528d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ai_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_79bd4fd1-b045-4f68-a59a-0504e562528d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ai_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ai_df",
              "summary": "{\n  \"name\": \"ai_df\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing Below"
      ],
      "metadata": {
        "id": "eBsPI2OpwqbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your output df will be like this I presume, please use the same variable names.\n",
        "import numpy as np\n",
        "# Creating a random one to test it out\n",
        "nlp_df = pd.DataFrame(np.random.rand(100, 1))\n",
        "\n",
        "print(nlp_df)\n",
        "\n",
        "import pandas as pd\n",
        "from joblib import load\n",
        "\n",
        "# Load the vectorizer\n",
        "loaded_vectorizer = load('/content/vectorizer.joblib')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = load('/content/random_forest_model.joblib')\n",
        "\n",
        "# Read the data from data.xlsx\n",
        "data_df = full_dataframe #pd.read_excel('/content/CIE L1_Aug2023 semester_OAT data.xlsx')\n",
        "\n",
        "# Assuming the text responses are in columns 7 onwards\n",
        "text_columns = data_df.columns[7:]\n",
        "\n",
        "# Iterate over each row and make predictions\n",
        "for index, row in data_df.iterrows():\n",
        "    # Concatenate all text responses into a single string https://www.canva.com/design/DAGCG5bJlhs/ZaWlO8EVoVCsPdDpJqnM0A/edit?utm_content=DAGCG5bJlhs&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton\n",
        "    answers_row = ' '.join(row[text_columns].astype(str))\n",
        "\n",
        "    # Transform the text using the loaded vectorizer\n",
        "    answers_row_vec = loaded_vectorizer.transform([answers_row])\n",
        "\n",
        "    # Make prediction for the row\n",
        "    prediction = loaded_model.predict(answers_row_vec)\n",
        "\n",
        "    # Print the predicted status\n",
        "    predicted_status = 'confirmed' if prediction[0] == 1 else 'not confirmed'\n",
        "    print(f\"Row {index + 1} - Predicted status: {predicted_status}\")"
      ],
      "metadata": {
        "id": "3wwkm6Xwwx78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from joblib import load\n",
        "\n",
        "# Load the vectorizer and model\n",
        "loaded_vectorizer = load('/content/vectorizer.joblib')\n",
        "loaded_model = load('/content/random_forest_model.joblib')\n",
        "\n",
        "# Assume data_df is already defined and includes the required data\n",
        "text_columns = data_df.columns[7:]\n",
        "\n",
        "# List to store each row's data\n",
        "data = []\n",
        "\n",
        "# Iterate over rows in the dataframe\n",
        "for index, row in full_dataframe.iterrows():\n",
        "    # Vectorize the given row\n",
        "    answers_row = ' '.join(row[text_columns].astype(str))\n",
        "    answers_row_vec = loaded_vectorizer.transform([answers_row])\n",
        "\n",
        "    # Predict the probability of the confirmed class\n",
        "    probability = loaded_model.predict_proba(answers_row_vec)[:, 1]\n",
        "\n",
        "    # Append dictionary to list\n",
        "    data.append({'probability': float(probability[0])})\n",
        "\n",
        "# Create DataFrame from list of dictionaries\n",
        "results_df = pd.DataFrame(data)\n",
        "\n",
        "# Optionally, to see the first few rows of your DataFrame:\n",
        "print(results_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H7ifGDEihcd",
        "outputId": "30a0671e-433a-45e3-d59f-1da192674bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   probability\n",
            "0     0.667667\n",
            "1     0.338087\n",
            "2     0.698056\n",
            "3     0.497621\n",
            "4     0.275978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjkDvGgqp9pq",
        "outputId": "c965245f-deae-4afd-bff5-7565aabd0f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00000000e+00 6.67666667e-01]\n",
            " [1.00000000e+00 3.38087302e-01]\n",
            " [2.00000000e+00 6.98055556e-01]\n",
            " [3.00000000e+00 4.97620851e-01]\n",
            " [4.00000000e+00 2.75977633e-01]\n",
            " [5.00000000e+00 4.61694444e-01]\n",
            " [6.00000000e+00 3.13472222e-01]\n",
            " [7.00000000e+00 6.30047619e-01]\n",
            " [8.00000000e+00 3.86698413e-01]\n",
            " [9.00000000e+00 4.30380952e-01]\n",
            " [1.00000000e+01 4.79769841e-01]\n",
            " [1.10000000e+01 6.80000000e-01]\n",
            " [1.20000000e+01 6.24333333e-01]\n",
            " [1.30000000e+01 4.47021284e-01]\n",
            " [1.40000000e+01 4.09662393e-01]\n",
            " [1.50000000e+01 5.91301587e-01]\n",
            " [1.60000000e+01 4.16320707e-01]\n",
            " [1.70000000e+01 4.70063492e-01]\n",
            " [1.80000000e+01 2.08222222e-01]\n",
            " [1.90000000e+01 4.71347403e-01]\n",
            " [2.00000000e+01 5.36611111e-01]\n",
            " [2.10000000e+01 6.30010101e-01]\n",
            " [2.20000000e+01 5.83777778e-01]\n",
            " [2.30000000e+01 5.98515152e-01]\n",
            " [2.40000000e+01 5.63931818e-01]\n",
            " [2.50000000e+01 4.09714286e-01]\n",
            " [2.60000000e+01 5.50833333e-01]\n",
            " [2.70000000e+01 2.19730159e-01]\n",
            " [2.80000000e+01 4.37134199e-01]\n",
            " [2.90000000e+01 3.18015873e-01]\n",
            " [3.00000000e+01 3.15777778e-01]\n",
            " [3.10000000e+01 6.24000000e-01]\n",
            " [3.20000000e+01 2.69138889e-01]\n",
            " [3.30000000e+01 3.08118326e-01]\n",
            " [3.40000000e+01 6.80101010e-01]\n",
            " [3.50000000e+01 3.64260878e-01]\n",
            " [3.60000000e+01 5.89416667e-01]\n",
            " [3.70000000e+01 7.01000000e-01]\n",
            " [3.80000000e+01 3.02232323e-01]\n",
            " [3.90000000e+01 3.13441558e-01]\n",
            " [4.00000000e+01 4.53093434e-01]\n",
            " [4.10000000e+01 3.60119048e-01]\n",
            " [4.20000000e+01 2.75848485e-01]\n",
            " [4.30000000e+01 3.53690476e-01]\n",
            " [4.40000000e+01 5.02956044e-01]\n",
            " [4.50000000e+01 3.11646825e-01]\n",
            " [4.60000000e+01 5.85555556e-01]\n",
            " [4.70000000e+01 4.39571429e-01]\n",
            " [4.80000000e+01 2.76565657e-01]\n",
            " [4.90000000e+01 5.68173882e-01]\n",
            " [5.00000000e+01 4.07142857e-01]\n",
            " [5.10000000e+01 4.66792929e-01]\n",
            " [5.20000000e+01 3.43573593e-01]\n",
            " [5.30000000e+01 6.94500000e-01]\n",
            " [5.40000000e+01 4.73787879e-01]\n",
            " [5.50000000e+01 5.32250000e-01]\n",
            " [5.60000000e+01 4.01727994e-01]\n",
            " [5.70000000e+01 6.36444444e-01]\n",
            " [5.80000000e+01 3.92454545e-01]\n",
            " [5.90000000e+01 2.69952381e-01]\n",
            " [6.00000000e+01 2.89674603e-01]\n",
            " [6.10000000e+01 6.61801587e-01]\n",
            " [6.20000000e+01 4.60000000e-01]\n",
            " [6.30000000e+01 1.84111111e-01]\n",
            " [6.40000000e+01 5.82260101e-01]\n",
            " [6.50000000e+01 3.59611111e-01]\n",
            " [6.60000000e+01 6.89000000e-01]\n",
            " [6.70000000e+01 4.45714286e-01]\n",
            " [6.80000000e+01 5.82916667e-01]\n",
            " [6.90000000e+01 2.99630647e-01]\n",
            " [7.00000000e+01 6.78333333e-01]\n",
            " [7.10000000e+01 4.05198413e-01]\n",
            " [7.20000000e+01 5.21230159e-01]\n",
            " [7.30000000e+01 3.64260878e-01]\n",
            " [7.40000000e+01 4.70230159e-01]\n",
            " [7.50000000e+01 2.05884921e-01]\n",
            " [7.60000000e+01 6.50000000e-01]\n",
            " [7.70000000e+01 3.89880952e-01]\n",
            " [7.80000000e+01 6.64000000e-01]\n",
            " [7.90000000e+01 7.07500000e-01]\n",
            " [8.00000000e+01 2.29049784e-01]\n",
            " [8.10000000e+01 3.64260878e-01]\n",
            " [8.20000000e+01 4.41333333e-01]\n",
            " [8.30000000e+01 6.88712121e-01]\n",
            " [8.40000000e+01 2.65670635e-01]\n",
            " [8.50000000e+01 5.93277778e-01]\n",
            " [8.60000000e+01 3.64260878e-01]\n",
            " [8.70000000e+01 4.33336580e-01]\n",
            " [8.80000000e+01 6.17333333e-01]\n",
            " [8.90000000e+01 2.54176768e-01]\n",
            " [9.00000000e+01 5.73730159e-01]\n",
            " [9.10000000e+01 5.47333333e-01]\n",
            " [9.20000000e+01 2.28000000e-01]\n",
            " [9.30000000e+01 2.35333333e-01]\n",
            " [9.40000000e+01 6.95714286e-01]\n",
            " [9.50000000e+01 3.59454545e-01]\n",
            " [9.60000000e+01 6.80952381e-01]\n",
            " [9.70000000e+01 6.28333333e-01]\n",
            " [9.80000000e+01 5.70000000e-01]\n",
            " [9.90000000e+01 3.01972222e-01]\n",
            " [1.00000000e+02 5.70666667e-01]\n",
            " [1.01000000e+02 5.57242063e-01]\n",
            " [1.02000000e+02 5.05515152e-01]\n",
            " [1.03000000e+02 3.64260878e-01]\n",
            " [1.04000000e+02 7.20000000e-01]\n",
            " [1.05000000e+02 6.55833333e-01]\n",
            " [1.06000000e+02 4.42797619e-01]\n",
            " [1.07000000e+02 2.92785714e-01]\n",
            " [1.08000000e+02 4.93333333e-01]\n",
            " [1.09000000e+02 3.43861111e-01]\n",
            " [1.10000000e+02 6.57035714e-01]\n",
            " [1.11000000e+02 2.44003247e-01]\n",
            " [1.12000000e+02 3.78626263e-01]\n",
            " [1.13000000e+02 6.81333333e-01]\n",
            " [1.14000000e+02 5.02830808e-01]\n",
            " [1.15000000e+02 6.41666667e-01]\n",
            " [1.16000000e+02 4.60735931e-01]\n",
            " [1.17000000e+02 5.48237374e-01]\n",
            " [1.18000000e+02 4.75265152e-01]\n",
            " [1.19000000e+02 5.83750000e-01]\n",
            " [1.20000000e+02 2.46098485e-01]\n",
            " [1.21000000e+02 1.94069264e-01]\n",
            " [1.22000000e+02 3.02603175e-01]\n",
            " [1.23000000e+02 4.19186508e-01]\n",
            " [1.24000000e+02 6.83416667e-01]\n",
            " [1.25000000e+02 2.63502165e-01]\n",
            " [1.26000000e+02 7.55777778e-01]\n",
            " [1.27000000e+02 5.79416667e-01]\n",
            " [1.28000000e+02 3.33968254e-01]\n",
            " [1.29000000e+02 3.71396825e-01]\n",
            " [1.30000000e+02 2.55732323e-01]\n",
            " [1.31000000e+02 6.90396825e-01]\n",
            " [1.32000000e+02 3.74680736e-01]\n",
            " [1.33000000e+02 1.67601371e-01]\n",
            " [1.34000000e+02 6.16000000e-01]\n",
            " [1.35000000e+02 3.93983100e-01]\n",
            " [1.36000000e+02 5.08349206e-01]\n",
            " [1.37000000e+02 6.40000000e-01]\n",
            " [1.38000000e+02 2.80285714e-01]\n",
            " [1.39000000e+02 6.60785714e-01]\n",
            " [1.40000000e+02 6.56666667e-01]\n",
            " [1.41000000e+02 2.59515152e-01]\n",
            " [1.42000000e+02 4.75000000e-01]\n",
            " [1.43000000e+02 4.40674603e-01]\n",
            " [1.44000000e+02 4.45000000e-01]\n",
            " [1.45000000e+02 6.14000000e-01]\n",
            " [1.46000000e+02 5.42702381e-01]\n",
            " [1.47000000e+02 6.42750000e-01]\n",
            " [1.48000000e+02 3.00813492e-01]\n",
            " [1.49000000e+02 4.35924603e-01]\n",
            " [1.50000000e+02 7.11666667e-01]\n",
            " [1.51000000e+02 3.64260878e-01]\n",
            " [1.52000000e+02 6.18190476e-01]\n",
            " [1.53000000e+02 5.90000000e-01]\n",
            " [1.54000000e+02 3.63777778e-01]\n",
            " [1.55000000e+02 6.78166667e-01]\n",
            " [1.56000000e+02 3.43555556e-01]\n",
            " [1.57000000e+02 2.88563492e-01]\n",
            " [1.58000000e+02 4.44150072e-01]\n",
            " [1.59000000e+02 5.65815657e-01]\n",
            " [1.60000000e+02 2.05301282e-01]\n",
            " [1.61000000e+02 7.48444444e-01]\n",
            " [1.62000000e+02 5.94527778e-01]\n",
            " [1.63000000e+02 7.74000000e-01]\n",
            " [1.64000000e+02 2.25194444e-01]\n",
            " [1.65000000e+02 5.73454545e-01]\n",
            " [1.66000000e+02 4.58121212e-01]\n",
            " [1.67000000e+02 2.77580808e-01]\n",
            " [1.68000000e+02 2.36073593e-01]\n",
            " [1.69000000e+02 6.33750000e-01]\n",
            " [1.70000000e+02 5.00515152e-01]\n",
            " [1.71000000e+02 2.45553030e-01]\n",
            " [1.72000000e+02 3.64260878e-01]\n",
            " [1.73000000e+02 4.16301587e-01]\n",
            " [1.74000000e+02 2.47416667e-01]\n",
            " [1.75000000e+02 5.92146825e-01]\n",
            " [1.76000000e+02 3.13174603e-01]\n",
            " [1.77000000e+02 5.55515152e-01]\n",
            " [1.78000000e+02 5.60714286e-01]\n",
            " [1.79000000e+02 6.39452381e-01]\n",
            " [1.80000000e+02 3.64260878e-01]\n",
            " [1.81000000e+02 4.03181818e-01]\n",
            " [1.82000000e+02 2.21305556e-01]\n",
            " [1.83000000e+02 3.64545815e-01]\n",
            " [1.84000000e+02 5.81467532e-01]\n",
            " [1.85000000e+02 4.22666667e-01]\n",
            " [1.86000000e+02 5.32916667e-01]\n",
            " [1.87000000e+02 2.28872294e-01]\n",
            " [1.88000000e+02 5.49555556e-01]\n",
            " [1.89000000e+02 6.34311688e-01]\n",
            " [1.90000000e+02 2.80939755e-01]\n",
            " [1.91000000e+02 5.93111111e-01]\n",
            " [1.92000000e+02 4.07273504e-01]\n",
            " [1.93000000e+02 2.76633117e-01]\n",
            " [1.94000000e+02 6.71454545e-01]\n",
            " [1.95000000e+02 1.98382756e-01]\n",
            " [1.96000000e+02 6.19000000e-01]\n",
            " [1.97000000e+02 6.31730159e-01]\n",
            " [1.98000000e+02 3.15750000e-01]\n",
            " [1.99000000e+02 5.81746032e-01]\n",
            " [2.00000000e+02 2.90702381e-01]\n",
            " [2.01000000e+02 4.50000000e-01]\n",
            " [2.02000000e+02 2.90684704e-01]\n",
            " [2.03000000e+02 4.35459596e-01]\n",
            " [2.04000000e+02 4.61119048e-01]\n",
            " [2.05000000e+02 3.22833333e-01]\n",
            " [2.06000000e+02 3.90992063e-01]\n",
            " [2.07000000e+02 6.78333333e-01]\n",
            " [2.08000000e+02 6.67222222e-01]\n",
            " [2.09000000e+02 6.36083333e-01]\n",
            " [2.10000000e+02 2.75809524e-01]\n",
            " [2.11000000e+02 6.75454545e-01]\n",
            " [2.12000000e+02 4.40073232e-01]\n",
            " [2.13000000e+02 3.47527778e-01]\n",
            " [2.14000000e+02 6.60000000e-01]\n",
            " [2.15000000e+02 3.64260878e-01]\n",
            " [2.16000000e+02 5.07404040e-01]\n",
            " [2.17000000e+02 3.79430736e-01]\n",
            " [2.18000000e+02 3.43480159e-01]\n",
            " [2.19000000e+02 5.98730159e-01]\n",
            " [2.20000000e+02 5.59714286e-01]\n",
            " [2.21000000e+02 5.70000000e-01]\n",
            " [2.22000000e+02 3.23333333e-01]\n",
            " [2.23000000e+02 6.15138889e-01]\n",
            " [2.24000000e+02 5.85230159e-01]\n",
            " [2.25000000e+02 4.52333333e-01]\n",
            " [2.26000000e+02 4.90952381e-01]\n",
            " [2.27000000e+02 4.73869048e-01]\n",
            " [2.28000000e+02 5.60000000e-01]\n",
            " [2.29000000e+02 3.05243506e-01]\n",
            " [2.30000000e+02 5.21357143e-01]\n",
            " [2.31000000e+02 2.26221917e-01]\n",
            " [2.32000000e+02 5.20542929e-01]\n",
            " [2.33000000e+02 2.54813492e-01]\n",
            " [2.34000000e+02 3.82268038e-01]\n",
            " [2.35000000e+02 2.79197691e-01]\n",
            " [2.36000000e+02 2.50053030e-01]\n",
            " [2.37000000e+02 5.04962121e-01]\n",
            " [2.38000000e+02 3.13333333e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outputting to the Excel File"
      ],
      "metadata": {
        "id": "dTeQbzdww2NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# I am dividing it here to normalize the score\n",
        "\n",
        "ai_df.loc[:, \"AI Component\"] = ai_df.sum(axis=1) / 5\n",
        "ai_df = ai_df[[\"AI Component\"]]\n",
        "print(ai_df)"
      ],
      "metadata": {
        "id": "2WRZPRzrw3rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Append the dataframes to the end of the first sheet irrespective of the name of the sheet of the excel file such that the dataframes are appended after the last column that has data on the excel file, don't replace any data on the sheet\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Append the dataframes to the end of the first sheet irrespective of the name of the sheet of the excel file such that the dataframes are appended after the last column that has data on the excel file, don't replace any data on the sheet\n",
        "def append_dataframes_to_excel(excel_file_path, dataframes):\n",
        "  with pd.ExcelWriter(excel_file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
        "    for dataframe in dataframes:\n",
        "      dataframe.to_excel(writer, sheet_name=writer.sheets.keys()[0], startrow=writer.sheets.values()[0].max_row, header=False, index=False)\n",
        "\n",
        "# Example usage\n",
        "excel_file_path = '/content/data.xlsx'\n",
        "dataframes = [ai_df, nlp_df]\n",
        "append_dataframes_to_excel(excel_file_path, dataframes)\n"
      ],
      "metadata": {
        "id": "3R_CdvP1xpy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Database"
      ],
      "metadata": {
        "id": "FlkGZiRC18Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3 as s\n",
        "import datetime\n",
        "\n",
        "def write_2_db(c, connection, param, value):\n",
        "  c.execute(\"\"\"\n",
        "    INSERT INTO GRAPH_DATA (PARAM, YEAR, MONTH, VALUE) VALUES (?, ?, ?, ?)\n",
        "  \"\"\", (param, datetime.date.today().year, datetime.date.today().month, value))\n",
        "\n",
        "  # Save the transaction\n",
        "  connection.commit()\n",
        "\n",
        "connection = s.connect(\"/content/base.sqlite\")\n",
        "\n",
        "c = connection.cursor()\n",
        "\n",
        "# Create a new table\n",
        "c.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS GRAPH_DATA (\n",
        "        PARAM TEXT NOT NULL,\n",
        "        YEAR INT NOT NULL,\n",
        "        MONTH INT NOT NULL,\n",
        "        VALUE TEXT NOT NULL\n",
        "    )\n",
        "\"\"\")\n",
        "\n",
        "write_2_db(c, connection, \"AI\", 122)\n",
        "\n",
        "# Read from database\n",
        "c.execute(\"SELECT * from GRAPH_DATA\")\n",
        "print(c.fetchall())\n"
      ],
      "metadata": {
        "id": "g08xEuLCXR9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(uploaded_file)"
      ],
      "metadata": {
        "id": "-HLOhaXAZ8nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XknbOL-YauC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}